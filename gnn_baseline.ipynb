{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "py37",
   "display_name": "py37",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user feature shape: (210369, 33)\n",
      "item feature shape: (357133, 44)\n",
      "user feature shape: (37964, 33)\n",
      "item feature shape: (45899, 44)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from utils import cprint, evaluationAUC_F1\n",
    "\n",
    "def load_data(prefix='train'):\n",
    "    item_table = pd.read_csv('task1_data/{}_item_feature_table.csv'.format(prefix))\n",
    "    user_table = pd.read_csv('task1_data/{}_user_feature_table.csv'.format(prefix))\n",
    "    print('user feature shape:', user_table.shape)\n",
    "    print('item feature shape:', item_table.shape)\n",
    "    \n",
    "    edge_table = pd.read_csv('task1_data/{}_e.csv'.format(prefix))\n",
    "    return item_table, user_table, edge_table\n",
    "\n",
    "train_item_table, train_user_table, train_edge_table = load_data('train')\n",
    "test_item_table, test_user_table, test_edge_table = load_data('test')\n"
   ]
  },
  {
   "source": [
    "import dgl\n",
    "import torch \n",
    "def load_dgl_graph(edge_table, user_table, item_table):\n",
    "    graph_data = {\n",
    "    ('user', 'buy', 'item'): (edge_table['userid'].values, edge_table['itemid'].values),\n",
    "    ('item', 'buyed', 'user'): (edge_table['itemid'].values, edge_table['userid'].values), \n",
    "    }\n",
    "    g = dgl.heterograph(graph_data)\n",
    "    print(g)\n",
    "    print(g.ntypes, g.etypes, g.canonical_etypes)\n",
    "    g.nodes['user'].data['feature'] = torch.from_numpy(user_table[user_table.columns[1:]].values).float()\n",
    "    g.nodes['item'].data['feature'] = torch.from_numpy(item_table[item_table.columns[1:]].values).float()\n",
    "    g.edges['buy'].data['label'] = torch.from_numpy(edge_table['label'].values).long()\n",
    "    return g\n",
    "\n",
    "train_g = load_dgl_graph(train_edge_table, train_user_table, train_item_table)\n",
    "test_g = load_dgl_graph(test_edge_table, test_user_table, test_item_table)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n",
      "Graph(num_nodes={'item': 357133, 'user': 210369},\n",
      "      num_edges={('item', 'buyed', 'user'): 500000, ('user', 'buy', 'item'): 500000},\n",
      "      metagraph=[('item', 'user', 'buyed'), ('user', 'item', 'buy')])\n",
      "['item', 'user'] ['buyed', 'buy'] [('item', 'buyed', 'user'), ('user', 'buy', 'item')]\n",
      "Graph(num_nodes={'item': 45899, 'user': 37964},\n",
      "      num_edges={('item', 'buyed', 'user'): 50000, ('user', 'buy', 'item'): 50000},\n",
      "      metagraph=[('item', 'user', 'buyed'), ('user', 'item', 'buy')])\n",
      "['item', 'user'] ['buyed', 'buy'] [('item', 'buyed', 'user'), ('user', 'buy', 'item')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, user_feature=32, item_feature=43, hidden_feature=64):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv = dglnn.HeteroGraphConv({\n",
    "            'buy' : dglnn.GraphConv(user_feature, hidden_feature, norm='none', weight=True, bias=True),\n",
    "            'buyed' : dglnn.GraphConv(item_feature, hidden_feature, norm='none', weight=True, bias=True)},\n",
    "        aggregate='sum')\n",
    "\n",
    "        self.cls = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_feature*2+user_feature+item_feature, hidden_feature),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_feature, hidden_feature),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_feature, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        self.bceloss = torch.nn.BCELoss()\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``h1``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['feature'], edges.dst['feature'], edges.src['h1'], edges.dst['h1']], 1)\n",
    "        return {'score': self.cls(h)}\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        h = self.conv(g, x)\n",
    "        g.nodes['user'].data['h1'] = h['user']\n",
    "        g.nodes['item'].data['h1'] = h['item']\n",
    "        # print(g.edges['buy'])\n",
    "       \n",
    "        g.apply_edges(self.apply_edges, etype='buy')\n",
    "        \n",
    "        scores = g.edges['buy'].data['score'].squeeze()\n",
    "        labels = g.edges['buy'].data['label'].float()\n",
    "        # print(scores.shape, labels.shape)\n",
    "        return scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN epochs 0 loss: 2.59\n",
      "TRAIN epochs 50 loss: 0.21\n",
      "TRAIN epochs 100 loss: 0.17\n",
      "TRAIN epochs 150 loss: 0.14\n",
      "TRAIN epochs 200 loss: 0.13\n",
      "TRAIN epochs 250 loss: 0.13\n",
      "TRAIN epochs 300 loss: 0.12\n",
      "TRAIN epochs 350 loss: 0.11\n",
      "TRAIN epochs 400 loss: 0.11\n",
      "TRAIN epochs 450 loss: 0.11\n",
      "\u001b[32m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "AUC: 0.8302622399999999\n",
      "max F1: 0.5157574896591556\n",
      "\u001b[32m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "best threshold: 0.24065584\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8302622399999999, 0.5157574896591556, 0.24065584)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import dgl.nn.pytorch as dglnn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda:0'\n",
    "sage1 = Model(hidden_feature=256).to(device)\n",
    "opt = torch.optim.SGD(sage1.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "for epoch in range(500):\n",
    "    scores, labels = sage1(train_g.to(device), {'user':train_g.nodes['user'].data['feature'].to(device), 'item':train_g.nodes['item'].data['feature'].to(device)})\n",
    "    loss = F.binary_cross_entropy(scores, labels)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"TRAIN epochs {} loss: {:.2f}\".format(epoch, loss.item()))\n",
    "    \n",
    "scores, labels = sage1(test_g.to(device), {'user':test_g.nodes['user'].data['feature'].to(device), 'item':test_g.nodes['item'].data['feature'].to(device)})\n",
    "scores, labels = scores.cpu().detach().numpy(), labels.cpu().detach().numpy()\n",
    "evaluationAUC_F1(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}